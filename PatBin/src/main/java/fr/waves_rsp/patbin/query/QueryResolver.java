package fr.waves_rsp.patbin.query;

import java.io.ByteArrayInputStream;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import fr.waves_rsp.patbin.PatBin;
import fr.waves_rsp.patbin.PatBinManipulation;
import fr.waves_rsp.patbin.compressor.BindingsHashTable;
import fr.waves_rsp.patbin.compressor.PatBinCompressor;
import fr.waves_rsp.patbin.query.continuous.SPARQLOperatorsResult;

public class QueryResolver {
	private SPARQLQuery queryElements;
	private BindingsHashTable table;
	private Map<Integer, Integer> statisticMap;
	private String staticEndpoint;

	private PatBin compressedQuery;
	private String streamPattern;

	/**
	 * Default constructor.
	 * 
	 * @param query
	 *            The query to be applied on the stream.
	 * @param streamPattern
	 *            The pattern associated to the stream (should be also
	 *            associated to a Kafka topic).
	 * @param bindingsTable
	 *            The bindings table used for the compression in the project.
	 * @param statisticMap
	 *            The statistic map (generated by LiteMat) for the predicates.
	 * @param staticEndpoint
	 *            The endpoint to access the static knowledge base.
	 */
	public QueryResolver(String query, String streamPattern, Map<String, Integer> bindingsTable,
			Map<Integer, Integer> statisticMap, String staticEndpoint) {
		SPARQLQuery queryRepresentation = SPARQLQueryManager.extractQueryElements(query);
		PatBinCompressor compressor = new PatBinCompressor();

		compressor.setBindingTable(new BindingsHashTable(bindingsTable));

		this.compressedQuery = compressor.compressFile(
				new ByteArrayInputStream(queryRepresentation.getWhere().getBytes(StandardCharsets.UTF_8)), "TTL");
		this.streamPattern = streamPattern;

		this.table = new BindingsHashTable(bindingsTable);
		this.queryElements = SPARQLQueryManager.extractQueryElements(query);
		if (queryElements.hasAggregate())
			queryElements.initializeAggregateValues(table);

		this.statisticMap = statisticMap;
		this.staticEndpoint = staticEndpoint;
	}

	/**
	 * Gives the pattern and the binding that need to be materialized in the
	 * stream. If no materialization is requires, returns null.
	 * 
	 * @param An
	 *            extract of stream, in triples format; used to precise the
	 *            query made on the static data in case some materialization is
	 *            required.
	 * @return The pattern and the binding to materialized, or null if no
	 *         materialization is required.
	 */
	public PatBin branchesToMaterialize(String streamExtract) {
		String queryPattern = compressedQuery.getPattern();

		String matPattern = PatBinManipulation.minusPattern(queryPattern,
				PatBinManipulation.jointPattern(streamPattern, queryPattern));

		if (matPattern.length() == 0)
			return null;
		else {
			String matBinding = PatBinManipulation.getMaterializedBin(
					new ByteArrayInputStream(streamExtract.getBytes()), table, matPattern, statisticMap,
					staticEndpoint);

			return new PatBin(matPattern, matBinding);
		}
	}

	/**
	 * Executes the query over a given stream. This method also deals with the
	 * need of materialization.
	 * 
	 * @param streamExtract
	 *            The stream extract on which the query must be applied.
	 * @return A map with the variables of the query as keys, and the results as
	 *         values, NULL if the query has no answer (e.g. is invalid)
	 */
	// TODO should be removed in the end
	public Map<String, String> processQuery(String streamExtract) {
		// compress the stream
		// (normally, it's already: we have the pattern from the kafka topic,
		// and only the bindings come from the stream)
		PatBinCompressor compressor = new PatBinCompressor();
		compressor.setBindingTable(table);
		PatBin streamPatBin = compressor
				.compressFile(new ByteArrayInputStream(streamExtract.getBytes(StandardCharsets.UTF_8)), "TTL");

		// checks if there is a need for materialization
		PatBin toMaterialize = branchesToMaterialize(streamExtract);
		if (toMaterialize != null)
			streamPatBin = PatBinManipulation.generateNewStreamBin(streamPatBin, toMaterialize, table);

		// the indexes of the query's variables in the binding
		List<Integer> variablesPositions = SPARQLQueryManager.getVariablesPositionInBin(queryElements, table);
		List<String> queryResult = queryOnStream(compressedQuery, streamPatBin, variablesPositions);

		// if there is no indexes, the query is not valid.
		if (queryResult == null)
			return null;

		// add the values for the aggregates here (if needed)
		SPARQLOperatorsResult.processAggregates(queryElements, compressedQuery, streamPatBin);

		// otherwise, we can build & return the result
		return QueryResolver.buildResult(queryElements, queryResult);
	}

	public void initializeQuery(String streamExtract) {
		// compress the stream
		// (normally, it's already: we have the pattern from the kafka topic,
		// and only the bindings come from the stream)
		PatBinCompressor compressor = new PatBinCompressor();
		compressor.setBindingTable(table);
		PatBin streamPatBin = compressor
				.compressFile(new ByteArrayInputStream(streamExtract.getBytes(StandardCharsets.UTF_8)), "TTL");

		// checks if there is a need for materialization
		PatBin toMaterialize = branchesToMaterialize(streamExtract);
		if (toMaterialize != null)
			streamPatBin = PatBinManipulation.generateNewStreamBin(streamPatBin, toMaterialize, table);

	}

	public Map<String, String> execute(String streamBinding) {
		PatBin streamPatBin = new PatBin(streamPattern, streamBinding);

		// the indexes of the query's variables in the binding
		List<Integer> variablesPositions = SPARQLQueryManager.getVariablesPositionInBin(queryElements, table);
		List<String> queryResult = queryOnStream(compressedQuery, streamPatBin, variablesPositions);

		// if there is no indexes, the query is not valid.
		if (queryResult == null)
			return null;

		// add the values for the aggregates here (if needed)
		SPARQLOperatorsResult.processAggregates(queryElements, compressedQuery, streamPatBin);

		// otherwise, we can build & return the result
		return QueryResolver.buildResult(queryElements, queryResult);
	}

	/**
	 * Applies the query to the stream.
	 * 
	 * @param queryPatBin
	 *            The compressed form of the query.
	 * @param streamPatBin
	 *            The compressed form of the binding.
	 * @param valuesIndexes
	 *            The indexes of the variables of the query in the binding.
	 * @return The values of the variables if the query can be applied on the
	 *         stream, null otherwise.
	 */
	public static List<String> queryOnStream(PatBin queryPatBin, PatBin streamPatBin, List<Integer> valuesIndexes) {
		List<String> variablesValues = new ArrayList<String>();
		List<String> splitStreamBinding = PatBinManipulation.getUsefulStreamBinding(queryPatBin, streamPatBin);

		// do the final check
		String[] splitQueryBinding = queryPatBin.getBinding().split(";", -1);
		if (splitQueryBinding.length != splitStreamBinding.size())
			return null;

		for (int i = 0; i < splitQueryBinding.length; i++)
			if (valuesIndexes.contains(i))
				variablesValues.add(splitStreamBinding.get(i));
			else if (!validateStandardBinding(splitQueryBinding[i], splitStreamBinding.get(i)))
				return null;

		// send the values of the variables (in order) if all is well
		for (int i : valuesIndexes)
			variablesValues.add(splitStreamBinding.get(i));

		return variablesValues;
	}

	/**
	 * Verifies if a value from a stream binding is valid according to the value
	 * at the corresponding place in the query. Does not take into account
	 * variables (both standard and aggregate ones).
	 * 
	 * @param binQuery
	 *            The value from the binding of the query.
	 * @param binStream
	 *            The value from the binding of the stream.
	 * @return true if the value of the stream is valid, false otherwise.
	 */
	public static boolean validateStandardBinding(String binQuery, String binStream) {
		// if the query has no requirement at this position, it's ok
		if (binQuery.equals(" "))
			return true;

		// if the bindings are equal, it's ok
		if (binQuery.equals(binStream))
			return true;

		// if it is a filter
		if (binQuery.startsWith("<")) {
			if (binQuery.charAt(1) == '=') {
				if (Float.parseFloat(binStream) <= Float.parseFloat(binQuery.substring(2)))
					return true;
			} else {
				if (Float.parseFloat(binStream) < Float.parseFloat(binQuery.substring(1)))
					return true;
			}
		} else if (binQuery.startsWith(">")) {
			if (binQuery.charAt(1) == '=') {
				if (Float.parseFloat(binStream) >= Float.parseFloat(binQuery.substring(2)))
					return true;
			} else {
				if (Float.parseFloat(binStream) > Float.parseFloat(binQuery.substring(1)))
					return true;
			}
		} else if (binQuery.startsWith("="))
			if (Float.parseFloat(binStream) == Float.parseFloat(binQuery.substring(1)))
				return true;

		// in any other case, it's not ok
		return false;
	}

	/**
	 * Deals with the aggregates. Verifies first that they answer the query
	 * (HAVING clause in the query), and compute the rsult according to the
	 * aggregate itself (avg, max, etc...).
	 * 
	 * @return A map with the variable in the aggregate as the key, or the
	 *         replacement if AS has been specified in the query. The values are
	 *         the result computed for each aggregates. The result should e void
	 *         if there is no value stored, and null if the aggregates are
	 *         incorrect (HAVING is incorrect).
	 */
	public Map<String, String> processAggregates() {
		if (!SPARQLOperatorsResult.aggregatesAreValid(queryElements))
			return null;
		else
			return SPARQLOperatorsResult.getAggregatesResult(queryElements);
	}

	/**
	 * Builds properly the result of a query.
	 * 
	 * @param query
	 *            The query that has been executed.
	 * @param result
	 *            The result of the query, ordered according to its SELECT
	 *            variables.
	 * @return A map with the select variable as key, and its value as value.
	 */
	private static Map<String, String> buildResult(SPARQLQuery query, List<String> result) {
		Map<String, String> resMap = new HashMap<String, String>();

		int id1 = 0;
		for (String key : query.getSelectVariables().keySet()) {
			resMap.put(key, result.get(id1));
			id1++;
		}

		return resMap;
	}
}
